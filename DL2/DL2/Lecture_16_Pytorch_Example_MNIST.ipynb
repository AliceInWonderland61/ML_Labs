{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be75_Vyt5eNL"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import requests\n",
        "\n",
        "download_root = './data/mnist'\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "batch_size = 200\n",
        "dataset_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "\n",
        "from torch.optim import optimizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.99 ** epoch)\n",
        "\n",
        "# train\n",
        "n_epoch = 3\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    for idx, (x, y) in enumerate(dataset_train):\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        train_losses.append(loss.item())\n",
        "        train_acc.append( (torch.max(pred, 1)[1] == y).sum()/batch_size )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #scheduler.step()\n",
        "    print('epoch: {}, loss:{}, acc:{}'.format(epoch, sum(train_losses)/(idx+1), sum(train_acc)/(idx+1) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osKlctce7MlI",
        "outputId": "6d52ba35-1196-4e35-c4a5-237e234aa735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss:0.5188223198056221, acc:0.8323662281036377\n",
            "epoch: 2, loss:0.2760962576667468, acc:0.9174162745475769\n",
            "epoch: 3, loss:0.2696163118382295, acc:0.9199332594871521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = DataLoader(test_dataset, batch_size=batch_size)\n",
        "test_acc = []\n",
        "for i, (x, y) in enumerate(dataset_test):\n",
        "    test_pred = model(x)\n",
        "    test_acc.append((torch.max(test_pred, 1)[1] == y).sum()/batch_size)\n",
        "print('test acc:{}'.format(sum(test_acc)/(len(test_acc) )) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_xJIHOeLVdS",
        "outputId": "d7ddc803-6152-4e00-e104-9ac2c679ead6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test acc:0.9220998287200928\n"
          ]
        }
      ]
    }
  ]
}